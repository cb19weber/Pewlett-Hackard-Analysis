# Pewlett-Hackard-Analysis

## Overview of Project
Module 7 of DU's Data Analytics bootcamp was all about getting accustomed to SQL and some tools to build databases and tables, and then query those datasets to create new tables based on requested information and export that information in .csv format. This project required the development of understanding entity relationship diagrams, and then applying that understanding to build queries that joined, filtered, created, and exported necessary data.

### Purpose
The specific purpose of this work is to work with an employee database to aid "Pewlett Hackard" in preparations for a potential mass exodus of current employees due to retirement, and then later to explore which currently employees might be good candidates for further training through a mentorship program as older employees transition away from the company.

## Analysis and Challenges

### Analysis of the Impact of Pending Retirements on Pewlett Hackard (Module)
The guided module helped to build an initial skillset applying SQL to harvest information and make the underlying data more useful. A variety of tables were built in the process, probably at a high level the most useful was the retirees by department to really give insight into the potential impact of an aging employee base. Pewlett Hackard is a relatively large company, with an underlying employee dataset of over 300,000 records. Being able to dig into that data and theorize the impact of employee transition is a powerful tool for the company to strategically prepare for the company's future.

After getting into the data, the retirees by department was an exceedingly useful table based on the initial premise of employees potential to retire based on age. The data certainly revealed the departments most heavily impacted based on the projection: Production and Development. With the datasets available, and particularly in light of employment trends in post-pandemic society, there are undoubtedly more projections that could be analyzed. It would be great to examine salary quartiles for each departmental role, and attempt to stem the tide of resignations by bringing highly valued, but potentially underpaid, employees up to the higher quartiles for their role within the company. This would also be especially useful to compare with market data for salaries based on title and industry.

### Further Retirement Impact Analysis and Building a Mentorship Program (Challenge)
The challenge portion expanded on the retirement impact analysis by providing an extensive list of employees likely to retire, and then summarized by title. Overwhelmingly, the largest group of potential retirees are senior engineers and senior staff, with notably a very small impact to the management team.

The challenge portion then transitioned into developing a mentorship program. The underlying projection was rather simply based on age of employee, but certainly time with the company and other factors could be implemented to produce a nice dataset and report. While the mentorship eligibility program offered a much smaller sample size than the projected retirement tables (a mere 1,500 compared to almost 33,000 projected retirees), the underlying projection assumptions could easily be manipulated to render a larger group of internal candidates.

### Challenges and Difficulties Encountered
We were told at the beginning of the week that learning the basics of SQL is pretty straight-forward and can be done in a relatively small amount of time. I've definitely already developed a comfort level with it and can easily see how I might apply this in building relational tables in my current role. As a relatively new, startup company, being able to have a solid grip on data is paramount to future growth. We have conversations on a daily basis of how to clean up and streamline our data pipeline. Packaging SQL with Python (and associated libraries) is going to be a powerful tool to help provide better data analysis to my company.

The specific challenges I encountered during the challenge mainly dealt with having to research a bit of syntax for some of the query mods. There are plenty of resources availabe to aid in this research and much of it was very straight-forward and quick to pick up. I've also added SQL to my HackerRank profile to continue practicing along with my Python skills on a daily basis.

I believe the real challenge is understanding the data available and developing solid ERD's to be able to navigate, compile, and use the relationships. The better understanding I can build of relationships within multiple tables in a database, the more efficient I can be in building useful queries and tables to tell the story behind all of that data.

## Results
The queries I used and the tables generated are contained in the 'Queries' and 'Data' folders, respectively. SQL is one of the foundational tools for data analysis and I am pleased to have developed a comfort level with it.